import streamlit as st
import pandas as pd
import os
import sys

# Add v1_code and vgui2.0 to path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', 'v1_code')))
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from data_loader import DataLoader
from utils import generate_synthetic_data, create_limits_df, InMemoryLoader

st.set_page_config(page_title="ë°ì´í„° ì„¤ì •", page_icon="âš™ï¸", layout="wide")

st.title("âš™ï¸ ë°ì´í„° ì„¤ì • (Data Configuration)")

tab1, tab2 = st.tabs(["ğŸ“‚ ì‹¤ì œ ë°ì´í„° ë¡œë“œ (Real Data)", "ğŸ§ª ê°€ìƒ ë°ì´í„° ìƒì„± (Synthetic Data)"])

# --- Tab 1: Load Real Data ---
with tab1:
    st.header("ê¸°ì¡´ ë°ì´í„° ë¡œë“œ")
    
    data_source = st.radio("ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ", ["ë””ë ‰í† ë¦¬ (CSV íŒŒì¼ë“¤)", "ë‹¨ì¼ CSV íŒŒì¼ ì—…ë¡œë“œ"])
    
    if data_source == "ë””ë ‰í† ë¦¬ (CSV íŒŒì¼ë“¤)":
        default_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', 'v1_code', 'scenario_data'))
        input_dir = st.text_input("ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ", value=default_dir)
        
        if st.button("ë””ë ‰í† ë¦¬ì—ì„œ ë¡œë“œ"):
            if os.path.exists(input_dir):
                try:
                    loader = DataLoader(input_dir)
                    loader.load_data()
                    st.session_state['data_loader'] = loader
                    st.session_state['data_source_type'] = 'Real'
                    st.success(f"ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë¨: {len(loader.df)} í–‰ (ë””ë ‰í† ë¦¬)")
                except Exception as e:
                    st.error(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            else:
                st.error("ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                
    elif data_source == "ë‹¨ì¼ CSV íŒŒì¼ ì—…ë¡œë“œ":
        uploaded_file = st.file_uploader("CSV íŒŒì¼ ì„ íƒ", type="csv")
        if uploaded_file is not None:
            if st.button("CSV ë¡œë“œ"):
                try:
                    df = pd.read_csv(uploaded_file)
                    # Basic validation
                    if 'Dataset' not in df.columns:
                        st.warning("CSVì— 'Dataset' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë‘ 'ASRP'ë¡œ ê°€ì •í•©ë‹ˆë‹¤.")
                        df['Dataset'] = 'ASRP'
                    
                    # Create a mock loader
                    loader = InMemoryLoader(df)
                    st.session_state['data_loader'] = loader
                    st.session_state['data_source_type'] = 'Real'
                    st.success(f"ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë¨: {len(df)} í–‰")
                except Exception as e:
                    st.error(f"CSV ì½ê¸° ì˜¤ë¥˜: {e}")

# --- Tab 2: Generate Synthetic Data ---
with tab2:
    st.header("ê°€ìƒ ë°ì´í„° ìƒì„±ê¸°")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.subheader("1. ìˆ˜ëŸ‰ ì„¤ì • (Quantity)")
        n_qim = st.number_input("QIM (ì´ˆê¸°) ìˆ˜ëŸ‰", value=200, step=10)
        n_asrp = st.number_input("ASRP (ì €ì¥) ìˆ˜ëŸ‰", value=50, step=10)
        n_overhaul = st.number_input("Overhaul (ì°½ì •ë¹„) ìˆ˜ëŸ‰", value=200, step=10)
        
    with col2:
        st.subheader("2. ì‹œì  ì„¤ì • (Timing)")
        asrp_range = st.slider("ASRP ìš´ìš©ì›” ë²”ìœ„", 0, 240, (96, 144))
        overhaul_range = st.slider("Overhaul ìš´ìš©ì›” ë²”ìœ„", 0, 240, (108, 132))
        
    with col3:
        st.subheader("3. ë…¸í›„í™” ì„¤ì • (Degradation)")
        degrading_items_str = st.text_input("ë…¸í›„í™” ì ìš© í•­ëª© (ì‰¼í‘œë¡œ êµ¬ë¶„)", value="23, 24, 25, 26, 27")
        drift_rate = st.slider("ë³€í™”ìœ¨ (ì›”ë³„ í‰ê·  ê°ì†ŒëŸ‰)", 0.0, 0.1, 0.05, step=0.01)
        noise_growth = st.slider("ë¶„ì‚° ì¦ê°€ìœ¨ (Noise Growth)", 1.0, 5.0, 1.0, step=0.1)
        
    if st.button("ê°€ìƒ ë°ì´í„° ìƒì„±"):
        try:
            # Parse items
            degrading_items = [int(x.strip()) for x in degrading_items_str.split(',') if x.strip().isdigit()]
            
            with st.spinner("ë°ì´í„° ìƒì„± ì¤‘..."):
                df = generate_synthetic_data(
                    n_qim=n_qim, n_asrp=n_asrp, n_overhaul=n_overhaul,
                    asrp_time_range=asrp_range, overhaul_time_range=overhaul_range,
                    degrading_items=degrading_items, drift_rate=drift_rate, noise_growth=noise_growth
                )
                
                limits_df = create_limits_df()
                loader = InMemoryLoader(df, limits_df)
                
                st.session_state['data_loader'] = loader
                st.session_state['data_source_type'] = 'Synthetic'
                
                st.success(f"ìƒì„± ì™„ë£Œ: ì´ {len(df)} í–‰ (QIM:{n_qim}, ASRP:{n_asrp}, Overhaul:{n_overhaul})")
                st.dataframe(df.head())
                
        except Exception as e:
            st.error(f"ë°ì´í„° ìƒì„± ì˜¤ë¥˜: {e}")

# Check status
if st.session_state.get('data_loader'):
    st.info(f"í˜„ì¬ ë¡œë“œëœ ë°ì´í„°: {st.session_state['data_source_type']} ë°ì´í„° ({len(st.session_state['data_loader'].df)} í–‰)")
    st.markdown("ğŸ‘‰ **'ë¶„ì„ ëŒ€ì‹œë³´ë“œ (Analysis Dashboard)' í˜ì´ì§€ë¡œ ì´ë™í•˜ì—¬ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.**")
